{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Feb 12 14:20:27 2021\n",
    "\n",
    "@author: erce\n",
    "\"\"\"\n",
    "import pathlib\n",
    "# Get the current path\n",
    "currentPath = pathlib.Path().absolute()\n",
    "import sys\n",
    "sys.path.insert(0, str(currentPath) + '/..')\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pysansa.rdf.rdf import Rdf\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Creating SparkConfig, SparkContext and SparkSession\n",
    "SparkContext uses our SANSA-Stack jar with dependencies included\n",
    "\"\"\"\n",
    "# Spark Session and Config\n",
    "conf = SparkConf().set(\"spark.jars\", str(currentPath) + \"../../pysansa/myjars/SANSA_all_dep_NO_spark.jar\") \n",
    "sc = SparkContext.getOrCreate(conf=conf)\n",
    "# Spark object\n",
    "spark = sc._jvm.org.apache.spark.sql.SparkSession.builder().master(\"local\") \\\n",
    "                        .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "                        .config(\"spark.sql.legacy.allowUntypedScalaUDF\", \"true\").appName(\"SansaRDF\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Creating Rdf Object from SANSA-Stack RDF Python Wrapper\n",
    "\"\"\"\n",
    "# Rdf object\n",
    "rdf = Rdf(sc)\n",
    "# Initialize Rdf Reader\n",
    "rdfReader = rdf.initializeRdfReader(spark)\n",
    "# Read triples from the given path\n",
    "triples = rdf.readTriples(rdfReader, path = 'file:///' + str(currentPath) + '../../data/rdf.nt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Element: http://commons.dbpedia.org/resource/Template:Cc-by-1.0 @http://commons.dbpedia.org/property/version \"1\"^^http://www.w3.org/2001/XMLSchema#integer\n",
      "\n",
      "2. Element: http://commons.dbpedia.org/resource/Category:Events @http://commons.dbpedia.org/property/de \"Ereignis, Veranstaltung.\"@en\n",
      "\n",
      "3. Element: http://commons.dbpedia.org/resource/Category:Events @http://commons.dbpedia.org/property/en \"Events\"@en\n",
      "\n",
      "4. Element: http://commons.dbpedia.org/resource/Category:Events @http://commons.dbpedia.org/property/fr \"Événements.\"@en\n",
      "\n",
      "5. Element: http://commons.dbpedia.org/resource/Template:Cc-by-sa-1.0 @http://commons.dbpedia.org/property/version \"1\"^^http://www.w3.org/2001/XMLSchema#integer\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Running some examples with RDF Python Wrapper\n",
    "\"\"\"\n",
    "# Get triples as array\n",
    "triples = rdf.getTriples(5)\n",
    "# Print triples\n",
    "rdf.printTriples(triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of triples: 106\n",
      "RDF IO Package methods: \n",
      "['RDFDataFrameReader', 'RDFDataFrameWriter', 'RDFQuadsWriter', 'RDFReader', 'RDFWriter', 'SaveMode$', 'fromRow', 'toRow']\n",
      "RDF Triple methods: \n",
      "['$anonfun$$plus$plus$1', '$anonfun$aggregate$1', '$anonfun$aggregate$2', '$anonfun$aggregate$3', '$anonfun$aggregate$4', '$anonfun$aggregate$4$adapted', '$anonfun$barrier$1', '$anonfun$cartesian$1', '$anonfun$checkpointAllMarkedAncestors$1', '$anonfun$checkpointAllMarkedAncestors$1$adapted', '$anonfun$checkpointRDD$1', '$anonfun$coalesce$1', '$anonfun$coalesce$2', '$anonfun$coalesce$3', '$anonfun$coalesce$3$adapted', '$anonfun$coalesce$4', '$anonfun$collect$1', '$anonfun$collect$2', '$anonfun$collect$3', '$anonfun$collect$4', '$anonfun$collect$4$adapted', '$anonfun$collectPartitions$1', '$anonfun$collectPartitions$2', '$anonfun$count$1', '$anonfun$count$1$adapted', '$anonfun$countApprox$1', '$anonfun$countApprox$2', '$anonfun$countApprox$3', '$anonfun$countApprox$3$adapted', '$anonfun$countApproxDistinct$1', '$anonfun$countApproxDistinct$2', '$anonfun$countApproxDistinct$3', '$anonfun$countApproxDistinct$4', '$anonfun$countApproxDistinct$5', '$anonfun$countApproxDistinct$6', '$anonfun$countApproxDistinct$7', '$anonfun$countApproxDistinct$8', '$anonfun$countByValue$1', '$anonfun$countByValue$2', '$anonfun$countByValueApprox$1', '$anonfun$countByValueApprox$2', '$anonfun$countByValueApprox$3', '$anonfun$countByValueApprox$4', '$anonfun$countByValueApprox$4$adapted', '$anonfun$countByValueApprox$5', '$anonfun$countByValueApprox$6', '$anonfun$dependencies$1', '$anonfun$dependencies$2', '$anonfun$distinct$1', '$anonfun$distinct$10', '$anonfun$distinct$11', '$anonfun$distinct$2', '$anonfun$distinct$3', '$anonfun$distinct$4', '$anonfun$distinct$5', '$anonfun$distinct$6', '$anonfun$distinct$7', '$anonfun$distinct$8', '$anonfun$distinct$9', '$anonfun$doCheckpoint$1', '$anonfun$doCheckpoint$2', '$anonfun$doCheckpoint$2$adapted', '$anonfun$doCheckpoint$3', '$anonfun$doCheckpoint$3$adapted', '$anonfun$filter$1', '$anonfun$filter$2', '$anonfun$filter$2$adapted', '$anonfun$first$1', '$anonfun$flatMap$1', '$anonfun$flatMap$2', '$anonfun$flatMap$2$adapted', '$anonfun$fold$1', '$anonfun$fold$2', '$anonfun$fold$3', '$anonfun$fold$3$adapted', '$anonfun$foreach$1', '$anonfun$foreach$2', '$anonfun$foreach$2$adapted', '$anonfun$foreachPartition$1', '$anonfun$foreachPartition$2', '$anonfun$foreachPartition$2$adapted', '$anonfun$getCreationSite$1', '$anonfun$getCreationSite$2', '$anonfun$getNarrowAncestors$1', '$anonfun$getNarrowAncestors$1$adapted', '$anonfun$getNarrowAncestors$2', '$anonfun$getNarrowAncestors$3', '$anonfun$getNarrowAncestors$3$adapted', '$anonfun$getNarrowAncestors$4', '$anonfun$getNarrowAncestors$4$adapted', '$anonfun$getNarrowAncestors$5', '$anonfun$getNarrowAncestors$5$adapted', '$anonfun$getOrCompute$1', '$anonfun$getOutputDeterministicLevel$1', '$anonfun$getOutputDeterministicLevel$2', '$anonfun$getOutputDeterministicLevel$2$adapted', '$anonfun$getOutputDeterministicLevel$3', '$anonfun$getOutputDeterministicLevel$3$adapted', '$anonfun$glom$1', '$anonfun$glom$2', '$anonfun$glom$2$adapted', '$anonfun$groupBy$1', '$anonfun$groupBy$2', '$anonfun$groupBy$3', '$anonfun$groupBy$4', '$anonfun$intersection$1', '$anonfun$intersection$2', '$anonfun$intersection$3', '$anonfun$intersection$4', '$anonfun$intersection$4$adapted', '$anonfun$intersection$5', '$anonfun$intersection$6', '$anonfun$intersection$7', '$anonfun$intersection$8', '$anonfun$intersection$8$adapted', '$anonfun$intersection$9', '$anonfun$isBarrier_$1', '$anonfun$isBarrier_$1$adapted', '$anonfun$isBarrier_$2', '$anonfun$isBarrier_$2$adapted', '$anonfun$isCheckpointedAndMaterialized$1', '$anonfun$isCheckpointedAndMaterialized$1$adapted', '$anonfun$isEmpty$1', '$anonfun$keyBy$1', '$anonfun$keyBy$2', '$anonfun$localCheckpoint$1', '$anonfun$localCheckpoint$2', '$anonfun$localCheckpoint$3', '$anonfun$map$1', '$anonfun$map$2', '$anonfun$map$2$adapted', '$anonfun$mapPartitions$1', '$anonfun$mapPartitions$2', '$anonfun$mapPartitions$2$adapted', '$anonfun$mapPartitionsInternal$1', '$anonfun$mapPartitionsInternal$2', '$anonfun$mapPartitionsInternal$2$adapted', '$anonfun$mapPartitionsWithIndex$1', '$anonfun$mapPartitionsWithIndex$2', '$anonfun$mapPartitionsWithIndex$2$adapted', '$anonfun$mapPartitionsWithIndex$3', '$anonfun$mapPartitionsWithIndex$4', '$anonfun$mapPartitionsWithIndex$4$adapted', '$anonfun$mapPartitionsWithIndexInternal$1', '$anonfun$mapPartitionsWithIndexInternal$2', '$anonfun$mapPartitionsWithIndexInternal$2$adapted', '$anonfun$max$1', '$anonfun$max$2', '$anonfun$min$1', '$anonfun$min$2', '$anonfun$new$1', '$anonfun$partitions$1', '$anonfun$partitions$2', '$anonfun$partitions$3', '$anonfun$partitions$3$adapted', '$anonfun$partitions$4', '$anonfun$persist$1', '$anonfun$persist$1$adapted', '$anonfun$pipe$1', '$anonfun$pipe$2', '$anonfun$pipe$3', '$anonfun$preferredLocations$1', '$anonfun$preferredLocations$2', '$anonfun$randomSampleWithRange$1', '$anonfun$randomSampleWithRange$1$adapted', '$anonfun$randomSplit$1', '$anonfun$randomSplit$2', '$anonfun$randomSplit$3', '$anonfun$randomSplit$4', '$anonfun$randomSplit$5', '$anonfun$randomSplit$6', '$anonfun$randomSplit$7', '$anonfun$reduce$1', '$anonfun$reduce$2', '$anonfun$reduce$3', '$anonfun$reduce$3$adapted', '$anonfun$reduce$4', '$anonfun$repartition$1', '$anonfun$retag$1', '$anonfun$sample$1', '$anonfun$sample$2', '$anonfun$sample$3', '$anonfun$saveAsObjectFile$1', '$anonfun$saveAsObjectFile$2', '$anonfun$saveAsObjectFile$3', '$anonfun$saveAsObjectFile$4', '$anonfun$saveAsTextFile$1', '$anonfun$saveAsTextFile$2', '$anonfun$saveAsTextFile$3', '$anonfun$saveAsTextFile$4', '$anonfun$saveAsTextFile$5', '$anonfun$scope$1', '$anonfun$sortBy$1', '$anonfun$subtract$1', '$anonfun$subtract$2', '$anonfun$subtract$3', '$anonfun$subtract$4', '$anonfun$subtract$5', '$anonfun$subtract$6', '$anonfun$subtract$7', '$anonfun$subtract$8', '$anonfun$take$1', '$anonfun$take$2', '$anonfun$take$3', '$anonfun$takeOrdered$1', '$anonfun$takeOrdered$2', '$anonfun$takeOrdered$3', '$anonfun$takeSample$1', '$anonfun$takeSample$2', '$anonfun$takeSample$3', '$anonfun$takeSample$4', '$anonfun$toDebugString$1', '$anonfun$toDebugString$1$adapted', '$anonfun$toDebugString$2', '$anonfun$toDebugString$3', '$anonfun$toDebugString$4', '$anonfun$toDebugString$5', '$anonfun$toDebugString$6', '$anonfun$toLocalIterator$1', '$anonfun$toLocalIterator$2', '$anonfun$toLocalIterator$3', '$anonfun$toLocalIterator$3$adapted', '$anonfun$toString$1', '$anonfun$toString$2', '$anonfun$top$1', '$anonfun$treeAggregate$1', '$anonfun$treeAggregate$2', '$anonfun$treeAggregate$3', '$anonfun$treeAggregate$4', '$anonfun$treeAggregate$5', '$anonfun$treeAggregate$6', '$anonfun$treeAggregate$6$adapted', '$anonfun$treeAggregate$7', '$anonfun$treeReduce$1', '$anonfun$treeReduce$2', '$anonfun$treeReduce$3', '$anonfun$treeReduce$4', '$anonfun$treeReduce$5', '$anonfun$treeReduce$6', '$anonfun$union$1', '$anonfun$unpersist$1', '$anonfun$zip$1', '$anonfun$zip$2', '$anonfun$zipPartitions$1', '$anonfun$zipPartitions$2', '$anonfun$zipPartitions$3', '$anonfun$zipPartitions$4', '$anonfun$zipPartitions$5', '$anonfun$zipPartitions$6', '$anonfun$zipWithIndex$1', '$anonfun$zipWithUniqueId$1', '$anonfun$zipWithUniqueId$2', '$anonfun$zipWithUniqueId$2$adapted', '$anonfun$zipWithUniqueId$3', '$lessinit$greater$default$3', '$lessinit$greater$default$4', '$lessinit$greater$default$5', '$plus$plus', 'aggregate', 'barrier', 'cache', 'cartesian', 'checkpoint', 'checkpointData', 'checkpointData_$eq', 'clearDependencies', 'coalesce', 'coalesce$default$2', 'coalesce$default$3', 'coalesce$default$4', 'collect', 'collectPartitions', 'compute', 'computeOrReadCheckpoint', 'conf', 'context', 'count', 'countApprox', 'countApprox$default$2', 'countApproxDistinct', 'countApproxDistinct$default$1', 'countByValue', 'countByValue$default$1', 'countByValueApprox', 'countByValueApprox$default$2', 'countByValueApprox$default$3', 'creationSite', 'dependencies', 'distinct', 'distinct$default$2', 'doCheckpoint', 'doubleRDDToDoubleRDDFunctions', 'elementClassTag', 'equals', 'filter', 'first', 'firstParent', 'flatMap', 'fold', 'foreach', 'foreachPartition', 'getCheckpointFile', 'getClass', 'getCreationSite', 'getDependencies', 'getNarrowAncestors', 'getNumPartitions', 'getOrCompute', 'getOutputDeterministicLevel', 'getPartitions', 'getPreferredLocations', 'getStorageLevel', 'glom', 'groupBy', 'groupBy$default$4', 'hashCode', 'id', 'initializeForcefully', 'initializeLogIfNecessary', 'initializeLogIfNecessary$default$2', 'intersection', 'intersection$default$3', 'isBarrier', 'isBarrier_', 'isCheckpointed', 'isCheckpointedAndMaterialized', 'isEmpty', 'isLocallyCheckpointed', 'isReliablyCheckpointed', 'isTraceEnabled', 'iterator', 'keyBy', 'localCheckpoint', 'log', 'logDebug', 'logError', 'logInfo', 'logName', 'logTrace', 'logWarning', 'map', 'mapPartitions', 'mapPartitions$default$2', 'mapPartitionsInternal', 'mapPartitionsInternal$default$2', 'mapPartitionsWithIndex', 'mapPartitionsWithIndex$default$2', 'mapPartitionsWithIndexInternal', 'mapPartitionsWithIndexInternal$default$2', 'mapPartitionsWithIndexInternal$default$3', 'markCheckpointed', 'max', 'min', 'name', 'name_$eq', 'notify', 'notifyAll', 'numericRDDToDoubleRDDFunctions', 'org$apache$spark$internal$Logging$$log_', 'org$apache$spark$internal$Logging$$log__$eq', 'outputDeterministicLevel', 'parent', 'partitioner', 'partitions', 'persist', 'pipe', 'pipe$default$2', 'pipe$default$3', 'pipe$default$4', 'pipe$default$5', 'pipe$default$6', 'pipe$default$7', 'preferredLocations', 'prev', 'prev_$eq', 'randomSampleWithRange', 'randomSplit', 'randomSplit$default$2', 'rddToAsyncRDDActions', 'rddToOrderedRDDFunctions', 'rddToPairRDDFunctions', 'rddToPairRDDFunctions$default$4', 'rddToSequenceFileRDDFunctions', 'reduce', 'repartition', 'repartition$default$2', 'retag', 'sample', 'sample$default$3', 'saveAsObjectFile', 'saveAsTextFile', 'scope', 'setName', 'sortBy', 'sortBy$default$2', 'sortBy$default$3', 'sparkContext', 'subtract', 'subtract$default$3', 'take', 'takeOrdered', 'takeSample', 'takeSample$default$3', 'toDebugString', 'toJavaRDD', 'toLocalIterator', 'toString', 'top', 'treeAggregate', 'treeAggregate$default$4', 'treeReduce', 'treeReduce$default$2', 'union', 'unpersist', 'unpersist$default$1', 'wait', 'withScope', 'zip', 'zipPartitions', 'zipWithIndex', 'zipWithUniqueId']\n",
      "dict_keys(['io', 'mappings', 'model', 'ops', 'partition', 'qualityassesment', 'stats'])\n"
     ]
    }
   ],
   "source": [
    "# Count triples from the object\n",
    "size = rdf.count()\n",
    "# Print size of triples\n",
    "print(\"Size of triples: \" + str(size))\n",
    "# Print attributes of RDF/IO\n",
    "rdf.printRdfIOAttributes()\n",
    "# Print triple object attribute\n",
    "rdf.printTripleObjectAttributes()\n",
    "# Print Rdf class packages\n",
    "rdf.printRdfClassPackageList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RDFReader class methods: \n",
      "['$anonfun$nquads$1', '$anonfun$ntriples$4', '$anonfun$rdf$3', '$anonfun$rdfxml$2', '$anonfun$rdfxml$3', '$anonfun$trig$1', '$anonfun$trig$2', '$anonfun$trix$1', '$anonfun$trix$2', '$anonfun$turtle$2', '$anonfun$turtle$3', 'datasets', 'equals', 'getClass', 'hashCode', 'notify', 'notifyAll', 'nquads', 'nquads$default$1', 'ntriples', 'ntriples$default$1', 'rdf', 'rdfxml', 'toString', 'trig', 'trix', 'turtle', 'wait']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Example usage of different packages from Rdf class\n",
    "io package RDFReader\n",
    "\"\"\"\n",
    "reader = rdf.packagesDict[\"io\"].RDFReader(spark)\n",
    "print(\"RDFReader class methods: \")\n",
    "print(dir(reader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RDFWriter class methods: \n",
      "['$anonfun$saveAsNTriplesFile$1', 'equals', 'getClass', 'hashCode', 'notify', 'notifyAll', 'saveAsNTriplesFile', 'saveAsNTriplesFile$default$2', 'saveAsNTriplesFile$default$3', 'toString', 'wait']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Example usage of different packages from Rdf class\n",
    "io package RDFWriter\n",
    "\"\"\"\n",
    "writer = rdf.packagesDict[\"io\"].RDFWriter(rdf.triples)\n",
    "print(\"RDFWriter class methods: \")\n",
    "print(dir(writer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QualityAssessmentOperations class methods: \n",
      "['assessAmountOfTriples', 'assessCoverageDetail', 'assessCoverageScope', 'assessDereferenceableBackLinks', 'assessDereferenceableForwardLinks', 'assessDereferenceableUris', 'assessExtensionalConciseness', 'assessExternalSameAsLinks', 'assessHumanReadableLicense', 'assessInterlinkingCompleteness', 'assessLabeledResources', 'assessLiteralNumericRangeChecker', 'assessMachineReadableLicense', 'assessNoHashUris', 'assessPropertyCompleteness', 'assessQueryParamFreeURIs', 'assessSchemaCompleteness', 'assessShortURIs', 'assessXSDDatatypeCompatibleLiterals', 'equals', 'getClass', 'hashCode', 'notify', 'notifyAll', 'toString', 'wait']\n",
      "Triples assesment:  0.0\n",
      "Coverage scope assesment:  0.22641509433962265\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Example usage of different packages from Rdf class\n",
    "io package RDFWriter\n",
    "\"\"\"\n",
    "qualityassesment = rdf.packagesDict[\"qualityassesment\"].QualityAssessmentOperations(rdf.triples)\n",
    "print(\"QualityAssessmentOperations class methods: \")\n",
    "print(dir(qualityassesment))\n",
    "assesmentTriples = qualityassesment.assessAmountOfTriples()\n",
    "print(\"Triples assesment: \", assesmentTriples)\n",
    "assesmentCoverage = qualityassesment.assessCoverageDetail()\n",
    "print(\"Coverage scope assesment: \", assesmentCoverage)\n",
    "# Stop SparkContext to prevent overloading\n",
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
